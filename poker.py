# -*- coding: utf-8 -*-
"""poker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qdpQXIRr3HJOfv4nGyo9TeA-XeJtJ1fg
"""

# Import Libraries
import keras # Neural Network Library
from keras import layers # Layers to a neural network
from keras import optimizers # optimizers
import pandas as pd # Data Manipulation library
import numpy as np # Fast Numeric Computing library
import tensorflow as tf # Optimizers
import matplotlib.pyplot as plt # Plot library
from sklearn.preprocessing import MinMaxScaler, label_binarize
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import plot_model # Print the network

import urllib.request
urllib.request.urlretrieve("https://archive.ics.uci.edu/static/public/158/poker+hand.zip", "poker+hand.zip")

import zipfile
with zipfile.ZipFile("poker+hand.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/")

# Loading training dataset
data = pd.read_csv('poker-hand-training-true.data', delimiter=",")
# About the parameters
# Header=1: column names (day, month, year, ...) are in the line 1 of this CSV file.
# skiprows=[124,125,126,170]: this lines, which not contains valid data, are not imported. If this parameter is missing, all lines are imported.
# usecols=list(range(0,13)): The last column, which is named Classes, is not imported. If this parameter is missing, all columns are imported.

# inspecting columns and data types from "data" dataframe
data.info()

datatest = pd.read_csv('poker-hand-testing.data', delimiter=",")
datatest.info()

classes = data.iloc[:, 10]
data.drop(data.columns[[0]], axis=1, inplace=True)
scaler = MinMaxScaler()
print(scaler.fit(data))
MinMaxScaler()
data = pd.DataFrame(scaler.transform(data))

# Extrair as classes (target)
classestest = datatest.iloc[:, 10]
datatest.drop(datatest.columns[[0]], axis=1, inplace=True)

# Criar e fitar o scaler
scalertest = MinMaxScaler()
scalertest.fit(datatest)

# Transformar os dados usando o MESMO scaler que foi fitado
datatest = pd.DataFrame(scalertest.transform(datatest), columns=datatest.columns)

# Creating the training dataset
train_x = data
train_y = label_binarize(classes, classes=[0,1,2,3,4,5,6,7,8,9])

# Creating the testing dataset
test_x = datatest
test_y = label_binarize(classestest, classes=[0,1,2,3,4,5,6,7,8,9])

# Verifying dataset dimensions
print('The training dataset (inputs) dimensions are: ', train_x.shape)
print('The training dataset (outputs) dimensions are: ', train_y.shape)
print('The testing dataset (inputs) dimensions are: ', test_x.shape)
print('The testing dataset (outputs) dimensions are: ', test_y.shape)

def build_model():

  model = keras.Sequential([
        layers.Input(shape=[len(train_x.columns)]),
        layers.Dense(2, activation="relu"),
        layers.Dense(7, activation="relu"),
        layers.Dense(10, activation="softmax")
  ])

  # Defining the optimizer
  optimizer = tf.keras.optimizers.RMSprop(
      learning_rate = 0.001)

  # Mean Squared Error (MSE) is the default loss function in regression models
  model.compile(loss = 'categorical_crossentropy',
      optimizer = optimizer,
      metrics = ['categorical_crossentropy','accuracy'])

  return model

model = build_model()
model.summary()

EPOCHS = 100

history = model.fit(
    train_x, train_y, epochs = EPOCHS, verbose = 1
)

plt.plot(history.history['categorical_crossentropy'])
plt.title('Training Categorical Cross Entropy')
plt.ylabel('Categorical Cross Entropy')
plt.xlabel('Epoch')
plt.legend(['Error'], loc='upper right')
plt.savefig("mlp-class-lossfunction.png")
plt.show()

plt.plot(history.history['accuracy'])
plt.title('Training Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Accuracy'], loc='lower right')
plt.savefig("mlp-class-trainingaccuracy.png")
plt.show()

weights = model.get_weights() # return a numpy list of weights
print(type(weights))
print(weights)

test_predictions = model.predict(test_x) # predict randon activities with the built linear regression model
print(confusion_matrix(test_predictions.argmax(axis=1), test_y.argmax(axis=1)))
print(classification_report(test_predictions.argmax(axis=1), test_y.argmax(axis=1), target_names=["Nothing", "One pair", "Two pairs", "Three of a kind", "Straight",
    "Flush", "Full house", "Four of a kind", "Straight flush", "Royal flush"]))
print('The accuracy on the test set is equal to: %.4f ' % accuracy_score(test_predictions.argmax(axis=1), test_y.argmax(axis=1)))

cm = confusion_matrix(test_predictions.argmax(axis=1), test_y.argmax(axis=1))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Nothing", "One pair", "Two pairs", "Three of a kind", "Straight",
    "Flush", "Full house", "Four of a kind", "Straight flush", "Royal flush"
])
disp.plot(cmap="bwr")
plt.title('Confusion Matrix for Testing Set')
plt.savefig("mlp-class-confusionmatrix.png")
plt.show()

train_predictions = model.predict(train_x)
print(confusion_matrix(train_predictions.argmax(axis=1), train_y.argmax(axis=1)))
print(classification_report(train_predictions.argmax(axis=1), train_y.argmax(axis=1), target_names=["Nothing", "One pair", "Two pairs", "Three of a kind", "Straight",
    "Flush", "Full house"]))
print('The accuracy on the training set is equal to: %.4f ' % accuracy_score(train_predictions.argmax(axis=1), train_y.argmax(axis=1)))

# Save the model architecture as an image
plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)